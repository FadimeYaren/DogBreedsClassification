{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Imports & Environment\n",
        "# =========================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "from scipy.io import loadmat\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# ==========================================\n",
        "# CONFIG (Baseline ile AYNI)\n",
        "# ==========================================\n",
        "BASE_CONFIG = {\n",
        "    \"BASE_DIR\": \"/content/datasets/stanford_dogs\",\n",
        "    \"SPLIT_FOLDER\": \"stanford_dogs_split\",\n",
        "\n",
        "    \"IMG_SIZE\": 128,\n",
        "    \"VAL_SPLIT\": 0.1,\n",
        "    \"AUTOTUNE\": tf.data.AUTOTUNE,\n",
        "\n",
        "    \"EPOCHS\": 20,\n",
        "    \"EARLY_STOP\": True,\n",
        "    \"EARLY_STOP_PATIENCE\": 5,\n",
        "\n",
        "    \"SEED\": 42,\n",
        "}\n",
        "\n",
        "CNN_CONFIG = {\n",
        "    \"ID\": \"CNN_VARIANT_A_DEEPER\",\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"LEARNING_RATE\": 1e-3,\n",
        "    \"OPTIMIZER\": \"adam\",\n",
        "    \"DROPOUT\": 0.3,\n",
        "    \"USE_BATCHNORM\": True,\n",
        "    \"AUGMENT\": True,\n",
        "}\n",
        "\n",
        "CONFIG = BASE_CONFIG.copy()\n",
        "CONFIG.update(CNN_CONFIG)\n",
        "\n",
        "os.makedirs(CONFIG[\"BASE_DIR\"], exist_ok=True)\n",
        "\n",
        "SEED = CONFIG[\"SEED\"]\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"Active CONFIG:\")\n",
        "for k in sorted(CONFIG.keys()):\n",
        "    print(f\"  {k}: {CONFIG[k]}\")\n",
        "\n",
        "# ==========================================\n",
        "# DATASET PREPARATION (same logic)\n",
        "# ==========================================\n",
        "IMAGES_URL = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
        "LISTS_URL  = \"http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\"\n",
        "\n",
        "def download_if_not_exists(url, dest_path):\n",
        "    if os.path.exists(dest_path):\n",
        "        return\n",
        "    urllib.request.urlretrieve(url, dest_path)\n",
        "\n",
        "def extract_if_not_exists(tar_path, extract_to):\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    with tarfile.open(tar_path) as tar:\n",
        "        tar.extractall(extract_to)\n",
        "\n",
        "def create_train_test_split(base_dir, split_folder):\n",
        "    split_dir = os.path.join(base_dir, split_folder)\n",
        "    if os.path.exists(split_dir):\n",
        "        return split_dir\n",
        "\n",
        "    images_dir = os.path.join(base_dir, \"Images\")\n",
        "    train_mat_path = os.path.join(base_dir, \"train_list.mat\")\n",
        "    test_mat_path  = os.path.join(base_dir, \"test_list.mat\")\n",
        "\n",
        "    os.makedirs(split_dir, exist_ok=True)\n",
        "    train_root = os.path.join(split_dir, \"train\")\n",
        "    test_root  = os.path.join(split_dir, \"test\")\n",
        "    os.makedirs(train_root, exist_ok=True)\n",
        "    os.makedirs(test_root, exist_ok=True)\n",
        "\n",
        "    train_mat = loadmat(train_mat_path)\n",
        "    test_mat  = loadmat(test_mat_path)\n",
        "\n",
        "    def mat_to_list(mat):\n",
        "        out = []\n",
        "        for i in range(mat.shape[0]):\n",
        "            x = mat[i][0]\n",
        "            while isinstance(x, np.ndarray):\n",
        "                x = x[0]\n",
        "            out.append(str(x))\n",
        "        return out\n",
        "\n",
        "    train_files = mat_to_list(train_mat[\"file_list\"])\n",
        "    train_labels = train_mat[\"labels\"].reshape(-1)\n",
        "    test_files = mat_to_list(test_mat[\"file_list\"])\n",
        "    test_labels = test_mat[\"labels\"].reshape(-1)\n",
        "\n",
        "    for p, l in zip(train_files, train_labels):\n",
        "        c = f\"class_{int(l):03d}\"\n",
        "        os.makedirs(os.path.join(train_root, c), exist_ok=True)\n",
        "        shutil.copy(os.path.join(images_dir, p), os.path.join(train_root, c, os.path.basename(p)))\n",
        "\n",
        "    for p, l in zip(test_files, test_labels):\n",
        "        c = f\"class_{int(l):03d}\"\n",
        "        os.makedirs(os.path.join(test_root, c), exist_ok=True)\n",
        "        shutil.copy(os.path.join(images_dir, p), os.path.join(test_root, c, os.path.basename(p)))\n",
        "\n",
        "    return split_dir\n",
        "\n",
        "def prepare_dataset(cfg):\n",
        "    base_dir = cfg[\"BASE_DIR\"]\n",
        "    images_tar = os.path.join(base_dir, \"images.tar\")\n",
        "    lists_tar  = os.path.join(base_dir, \"lists.tar\")\n",
        "\n",
        "    download_if_not_exists(IMAGES_URL, images_tar)\n",
        "    download_if_not_exists(LISTS_URL, lists_tar)\n",
        "\n",
        "    if not os.path.exists(os.path.join(base_dir, \"Images\")):\n",
        "        extract_if_not_exists(images_tar, base_dir)\n",
        "    if not os.path.exists(os.path.join(base_dir, \"train_list.mat\")):\n",
        "        extract_if_not_exists(lists_tar, base_dir)\n",
        "\n",
        "    create_train_test_split(base_dir, cfg[\"SPLIT_FOLDER\"])\n",
        "\n",
        "prepare_dataset(CONFIG)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# DATASET LOADING\n",
        "# ==========================================\n",
        "SPLIT_DIR = os.path.join(CONFIG[\"BASE_DIR\"], CONFIG[\"SPLIT_FOLDER\"])\n",
        "\n",
        "train_ds_full = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_DIR, \"train\"),\n",
        "    image_size=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"]),\n",
        "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "    shuffle=True,\n",
        "    seed=CONFIG[\"SEED\"],\n",
        ")\n",
        "\n",
        "class_names = train_ds_full.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "val_batches = int(len(train_ds_full) * CONFIG[\"VAL_SPLIT\"])\n",
        "val_ds = train_ds_full.take(val_batches)\n",
        "train_ds = train_ds_full.skip(val_batches)\n",
        "\n",
        "test_ds = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_DIR, \"test\"),\n",
        "    image_size=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"]),\n",
        "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "val_ds   = val_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "test_ds  = test_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# CNN Variant A – Deeper Network\n",
        "# ONLY CHANGE: +1 Conv Block\n",
        "# ==========================================\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "def build_cnn_variant_a(input_shape, num_classes, cfg):\n",
        "    x_in = keras.Input(shape=input_shape)\n",
        "    x = layers.Rescaling(1./255)(x_in)\n",
        "    if cfg[\"AUGMENT\"]:\n",
        "        x = data_augmentation(x)\n",
        "\n",
        "    # Block 1\n",
        "    for f in [32, 64, 128, 256]:  # <-- EXTRA BLOCK (256)\n",
        "        x = layers.Conv2D(f, 3, padding=\"same\")(x)\n",
        "        if cfg[\"USE_BATCHNORM\"]:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(cfg[\"DROPOUT\"])(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(cfg[\"DROPOUT\"])(x)\n",
        "\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(x_in, out, name=cfg[\"ID\"])\n",
        "\n",
        "model = build_cnn_variant_a(\n",
        "    (CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"], 3),\n",
        "    num_classes,\n",
        "    CONFIG\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ==========================================\n",
        "# Compile & Train\n",
        "# ==========================================\n",
        "optimizer = keras.optimizers.Adam(learning_rate=CONFIG[\"LEARNING_RATE\"])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=CONFIG[\"EARLY_STOP_PATIENCE\"],\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=CONFIG[\"EPOCHS\"],\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "for x, y in test_ds:\n",
        "    p = model.predict(x, verbose=0)\n",
        "    y_true.extend(y.numpy())\n",
        "    y_pred.extend(np.argmax(p, axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Save results\n",
        "# ==========================================\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "model.save(\"results/CNN_VARIANT_A_DEEPER.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KfBlM1ySgO0P",
        "outputId": "86bb3fbe-5e8c-48c0-e372-b9e50f491b34"
      },
      "id": "KfBlM1ySgO0P",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Active CONFIG:\n",
            "  AUGMENT: True\n",
            "  AUTOTUNE: -1\n",
            "  BASE_DIR: /content/datasets/stanford_dogs\n",
            "  BATCH_SIZE: 32\n",
            "  DROPOUT: 0.3\n",
            "  EARLY_STOP: True\n",
            "  EARLY_STOP_PATIENCE: 5\n",
            "  EPOCHS: 20\n",
            "  ID: CNN_VARIANT_A_DEEPER\n",
            "  IMG_SIZE: 128\n",
            "  LEARNING_RATE: 0.001\n",
            "  OPTIMIZER: adam\n",
            "  SEED: 42\n",
            "  SPLIT_FOLDER: stanford_dogs_split\n",
            "  USE_BATCHNORM: True\n",
            "  VAL_SPLIT: 0.1\n",
            "Found 12000 files belonging to 120 classes.\n",
            "Found 8580 files belonging to 120 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_VARIANT_A_DEEPER\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_VARIANT_A_DEEPER\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling_4 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_10 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_11 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_12 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_13 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m30,840\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,840</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m486,968\u001b[0m (1.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">486,968</span> (1.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m486,008\u001b[0m (1.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">486,008</span> (1.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 56ms/step - accuracy: 0.0120 - loss: 4.8360 - val_accuracy: 0.0093 - val_loss: 4.8155\n",
            "Epoch 2/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.0155 - loss: 4.7155 - val_accuracy: 0.0127 - val_loss: 4.7577\n",
            "Epoch 3/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.0185 - loss: 4.6585 - val_accuracy: 0.0220 - val_loss: 4.6965\n",
            "Epoch 4/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.0236 - loss: 4.6110 - val_accuracy: 0.0135 - val_loss: 4.8256\n",
            "Epoch 5/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - accuracy: 0.0275 - loss: 4.5336 - val_accuracy: 0.0236 - val_loss: 4.5996\n",
            "Epoch 6/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - accuracy: 0.0316 - loss: 4.4712 - val_accuracy: 0.0245 - val_loss: 4.5230\n",
            "Epoch 7/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - accuracy: 0.0383 - loss: 4.3917 - val_accuracy: 0.0304 - val_loss: 4.5066\n",
            "Epoch 8/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.0442 - loss: 4.3195 - val_accuracy: 0.0431 - val_loss: 4.3570\n",
            "Epoch 9/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - accuracy: 0.0522 - loss: 4.2611 - val_accuracy: 0.0372 - val_loss: 4.4202\n",
            "Epoch 10/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - accuracy: 0.0610 - loss: 4.2107 - val_accuracy: 0.0507 - val_loss: 4.3225\n",
            "Epoch 11/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.0606 - loss: 4.1480 - val_accuracy: 0.0296 - val_loss: 4.5434\n",
            "Epoch 12/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - accuracy: 0.0650 - loss: 4.1148 - val_accuracy: 0.0236 - val_loss: 4.4206\n",
            "Epoch 13/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - accuracy: 0.0723 - loss: 4.0527 - val_accuracy: 0.0448 - val_loss: 4.4614\n",
            "Epoch 14/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0797 - loss: 4.0167 - val_accuracy: 0.0566 - val_loss: 4.2839\n",
            "Epoch 15/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0843 - loss: 3.9674 - val_accuracy: 0.0557 - val_loss: 4.3740\n",
            "Epoch 16/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0834 - loss: 3.9267 - val_accuracy: 0.0676 - val_loss: 4.1618\n",
            "Epoch 17/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0871 - loss: 3.8885 - val_accuracy: 0.0701 - val_loss: 4.1879\n",
            "Epoch 18/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0981 - loss: 3.8646 - val_accuracy: 0.0642 - val_loss: 4.2984\n",
            "Epoch 19/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0982 - loss: 3.8254 - val_accuracy: 0.0676 - val_loss: 4.2253\n",
            "Epoch 20/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.1081 - loss: 3.7948 - val_accuracy: 0.0819 - val_loss: 4.0757\n",
            "Test Accuracy: 0.0726\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   class_001     0.0000    0.0000    0.0000        52\n",
            "   class_002     0.1420    0.2706    0.1862        85\n",
            "   class_003     0.2241    0.0855    0.1238       152\n",
            "   class_004     0.0000    0.0000    0.0000        49\n",
            "   class_005     0.0000    0.0000    0.0000       114\n",
            "   class_006     0.1948    0.1705    0.1818        88\n",
            "   class_007     0.1837    0.0938    0.1241        96\n",
            "   class_008     0.0000    0.0000    0.0000        72\n",
            "   class_009     0.0526    0.0139    0.0220        72\n",
            "   class_010     0.0714    0.0216    0.0331       139\n",
            "   class_011     0.0488    0.0267    0.0345        75\n",
            "   class_012     0.0000    0.0000    0.0000        95\n",
            "   class_013     0.0000    0.0000    0.0000        87\n",
            "   class_014     0.0417    0.0141    0.0211        71\n",
            "   class_015     0.0580    0.0678    0.0625        59\n",
            "   class_016     0.1667    0.0566    0.0845        53\n",
            "   class_017     0.2308    0.2105    0.2202        57\n",
            "   class_018     0.0000    0.0000    0.0000        48\n",
            "   class_019     0.0571    0.0784    0.0661        51\n",
            "   class_020     0.0357    0.0085    0.0137       118\n",
            "   class_021     0.1667    0.0122    0.0227        82\n",
            "   class_022     0.0495    0.1034    0.0669        87\n",
            "   class_023     0.0769    0.0455    0.0571        88\n",
            "   class_024     0.1818    0.0208    0.0374        96\n",
            "   class_025     0.0265    0.0588    0.0366        51\n",
            "   class_026     0.0000    0.0000    0.0000       100\n",
            "   class_027     1.0000    0.0152    0.0299       132\n",
            "   class_028     0.0000    0.0000    0.0000        60\n",
            "   class_029     0.0741    0.0364    0.0488        55\n",
            "   class_030     0.0000    0.0000    0.0000        64\n",
            "   class_031     0.0385    0.0122    0.0185        82\n",
            "   class_032     0.0500    0.0139    0.0217        72\n",
            "   class_033     0.0000    0.0000    0.0000        79\n",
            "   class_034     0.0000    0.0000    0.0000        69\n",
            "   class_035     0.0795    0.0972    0.0875        72\n",
            "   class_036     0.1538    0.0235    0.0408        85\n",
            "   class_037     0.0000    0.0000    0.0000        64\n",
            "   class_038     0.0577    0.0526    0.0550        57\n",
            "   class_039     0.0000    0.0000    0.0000        97\n",
            "   class_040     0.2308    0.0588    0.0938       102\n",
            "   class_041     0.0000    0.0000    0.0000       102\n",
            "   class_042     0.0000    0.0000    0.0000        97\n",
            "   class_043     0.0000    0.0000    0.0000        96\n",
            "   class_044     0.0247    0.0250    0.0248        80\n",
            "   class_045     0.0667    0.1829    0.0977        82\n",
            "   class_046     0.0000    0.0000    0.0000        54\n",
            "   class_047     0.0247    0.0351    0.0290        57\n",
            "   class_048     0.0000    0.0000    0.0000        55\n",
            "   class_049     0.0534    0.1207    0.0741        58\n",
            "   class_050     0.0000    0.0000    0.0000       106\n",
            "   class_051     0.2727    0.0361    0.0638        83\n",
            "   class_052     0.0690    0.0357    0.0471        56\n",
            "   class_053     0.0622    0.1884    0.0935        69\n",
            "   class_054     0.0526    0.0349    0.0420        86\n",
            "   class_055     0.0333    0.0192    0.0244        52\n",
            "   class_056     0.0345    0.1373    0.0551        51\n",
            "   class_057     0.1667    0.0200    0.0357        50\n",
            "   class_058     0.0000    0.0000    0.0000        71\n",
            "   class_059     0.0345    0.0149    0.0208        67\n",
            "   class_060     0.1190    0.0962    0.1064        52\n",
            "   class_061     0.2500    0.0185    0.0345        54\n",
            "   class_062     0.0000    0.0000    0.0000        61\n",
            "   class_063     0.0897    0.3818    0.1453        55\n",
            "   class_064     0.0690    0.0377    0.0488        53\n",
            "   class_065     0.0556    0.0192    0.0286        52\n",
            "   class_066     0.0532    0.1000    0.0694        50\n",
            "   class_067     0.0524    0.1864    0.0818        59\n",
            "   class_068     0.0686    0.1400    0.0921        50\n",
            "   class_069     0.0000    0.0000    0.0000        59\n",
            "   class_070     0.0577    0.2353    0.0927        51\n",
            "   class_071     0.0471    0.5600    0.0870        50\n",
            "   class_072     0.0304    0.3000    0.0551        50\n",
            "   class_073     0.0736    0.4444    0.1263        54\n",
            "   class_074     0.0385    0.0200    0.0263        50\n",
            "   class_075     0.0000    0.0000    0.0000        50\n",
            "   class_076     0.1429    0.0192    0.0339        52\n",
            "   class_077     0.0263    0.0189    0.0220        53\n",
            "   class_078     0.0363    0.8519    0.0696        54\n",
            "   class_079     0.0597    0.1739    0.0889        69\n",
            "   class_080     0.1538    0.0702    0.0964        57\n",
            "   class_081     0.0000    0.0000    0.0000        53\n",
            "   class_082     0.0647    0.3600    0.1098        50\n",
            "   class_083     0.1167    0.1400    0.1273        50\n",
            "   class_084     0.1500    0.2308    0.1818        52\n",
            "   class_085     0.0000    0.0000    0.0000        52\n",
            "   class_086     0.1059    0.1800    0.1333        50\n",
            "   class_087     0.0000    0.0000    0.0000        84\n",
            "   class_088     0.1667    0.1176    0.1379        68\n",
            "   class_089     0.2014    0.2373    0.2179       118\n",
            "   class_090     0.0924    0.3333    0.1447        51\n",
            "   class_091     0.2907    0.2451    0.2660       102\n",
            "   class_092     0.2500    0.0196    0.0364        51\n",
            "   class_093     0.0000    0.0000    0.0000        56\n",
            "   class_094     0.1250    0.0192    0.0333        52\n",
            "   class_095     0.0000    0.0000    0.0000        59\n",
            "   class_096     0.0000    0.0000    0.0000        56\n",
            "   class_097     0.1132    0.0857    0.0976        70\n",
            "   class_098     0.0556    0.0200    0.0294        50\n",
            "   class_099     0.0000    0.0000    0.0000        78\n",
            "   class_100     0.0000    0.0000    0.0000        92\n",
            "   class_101     0.0847    0.2000    0.1190        50\n",
            "   class_102     0.1579    0.0275    0.0469       109\n",
            "   class_103     0.0323    0.0100    0.0153       100\n",
            "   class_104     0.2105    0.0364    0.0620       110\n",
            "   class_105     0.1579    0.0316    0.0526        95\n",
            "   class_106     0.1119    0.1416    0.1250       113\n",
            "   class_107     0.0000    0.0000    0.0000       118\n",
            "   class_108     0.1667    0.0252    0.0438       119\n",
            "   class_109     0.0000    0.0000    0.0000        96\n",
            "   class_110     0.1197    0.2414    0.1600        58\n",
            "   class_111     0.1562    0.0943    0.1176        53\n",
            "   class_112     0.0952    0.0247    0.0392        81\n",
            "   class_113     0.0000    0.0000    0.0000        55\n",
            "   class_114     0.0431    0.0980    0.0599        51\n",
            "   class_115     0.0694    0.0909    0.0787        55\n",
            "   class_116     0.0769    0.0169    0.0278        59\n",
            "   class_117     0.0581    0.0909    0.0709        55\n",
            "   class_118     0.1186    0.1250    0.1217        56\n",
            "   class_119     0.2500    0.1600    0.1951        50\n",
            "   class_120     0.3030    0.1449    0.1961        69\n",
            "\n",
            "    accuracy                         0.0726      8580\n",
            "   macro avg     0.0830    0.0812    0.0563      8580\n",
            "weighted avg     0.0930    0.0726    0.0554      8580\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}