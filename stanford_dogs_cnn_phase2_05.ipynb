{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Imports & Environment\n",
        "# =========================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "from scipy.io import loadmat\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# ==========================================\n",
        "# CONFIG (Baseline ile AYNI)\n",
        "# ==========================================\n",
        "BASE_CONFIG = {\n",
        "    \"BASE_DIR\": \"/content/datasets/stanford_dogs\",\n",
        "    \"SPLIT_FOLDER\": \"stanford_dogs_split\",\n",
        "\n",
        "    \"IMG_SIZE\": 128,\n",
        "    \"VAL_SPLIT\": 0.1,\n",
        "    \"AUTOTUNE\": tf.data.AUTOTUNE,\n",
        "\n",
        "    \"EPOCHS\": 20,\n",
        "    \"EARLY_STOP\": True,\n",
        "    \"EARLY_STOP_PATIENCE\": 5,\n",
        "\n",
        "    \"SEED\": 42,\n",
        "}\n",
        "\n",
        "CNN_CONFIG = {\n",
        "    \"ID\": \"CNN_VARIANT_A_DEEPER\",\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"LEARNING_RATE\": 1e-3,\n",
        "    \"OPTIMIZER\": \"adam\",\n",
        "    \"DROPOUT\": 0.3,\n",
        "    \"USE_BATCHNORM\": True,\n",
        "    \"AUGMENT\": True,\n",
        "}\n",
        "\n",
        "CONFIG = BASE_CONFIG.copy()\n",
        "CONFIG.update(CNN_CONFIG)\n",
        "\n",
        "os.makedirs(CONFIG[\"BASE_DIR\"], exist_ok=True)\n",
        "\n",
        "SEED = CONFIG[\"SEED\"]\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"Active CONFIG:\")\n",
        "for k in sorted(CONFIG.keys()):\n",
        "    print(f\"  {k}: {CONFIG[k]}\")\n",
        "\n",
        "# ==========================================\n",
        "# DATASET PREPARATION (same logic)\n",
        "# ==========================================\n",
        "IMAGES_URL = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
        "LISTS_URL  = \"http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\"\n",
        "\n",
        "def download_if_not_exists(url, dest_path):\n",
        "    if os.path.exists(dest_path):\n",
        "        return\n",
        "    urllib.request.urlretrieve(url, dest_path)\n",
        "\n",
        "def extract_if_not_exists(tar_path, extract_to):\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    with tarfile.open(tar_path) as tar:\n",
        "        tar.extractall(extract_to)\n",
        "\n",
        "def create_train_test_split(base_dir, split_folder):\n",
        "    split_dir = os.path.join(base_dir, split_folder)\n",
        "    if os.path.exists(split_dir):\n",
        "        return split_dir\n",
        "\n",
        "    images_dir = os.path.join(base_dir, \"Images\")\n",
        "    train_mat_path = os.path.join(base_dir, \"train_list.mat\")\n",
        "    test_mat_path  = os.path.join(base_dir, \"test_list.mat\")\n",
        "\n",
        "    os.makedirs(split_dir, exist_ok=True)\n",
        "    train_root = os.path.join(split_dir, \"train\")\n",
        "    test_root  = os.path.join(split_dir, \"test\")\n",
        "    os.makedirs(train_root, exist_ok=True)\n",
        "    os.makedirs(test_root, exist_ok=True)\n",
        "\n",
        "    train_mat = loadmat(train_mat_path)\n",
        "    test_mat  = loadmat(test_mat_path)\n",
        "\n",
        "    def mat_to_list(mat):\n",
        "        out = []\n",
        "        for i in range(mat.shape[0]):\n",
        "            x = mat[i][0]\n",
        "            while isinstance(x, np.ndarray):\n",
        "                x = x[0]\n",
        "            out.append(str(x))\n",
        "        return out\n",
        "\n",
        "    train_files = mat_to_list(train_mat[\"file_list\"])\n",
        "    train_labels = train_mat[\"labels\"].reshape(-1)\n",
        "    test_files = mat_to_list(test_mat[\"file_list\"])\n",
        "    test_labels = test_mat[\"labels\"].reshape(-1)\n",
        "\n",
        "    for p, l in zip(train_files, train_labels):\n",
        "        c = f\"class_{int(l):03d}\"\n",
        "        os.makedirs(os.path.join(train_root, c), exist_ok=True)\n",
        "        shutil.copy(os.path.join(images_dir, p), os.path.join(train_root, c, os.path.basename(p)))\n",
        "\n",
        "    for p, l in zip(test_files, test_labels):\n",
        "        c = f\"class_{int(l):03d}\"\n",
        "        os.makedirs(os.path.join(test_root, c), exist_ok=True)\n",
        "        shutil.copy(os.path.join(images_dir, p), os.path.join(test_root, c, os.path.basename(p)))\n",
        "\n",
        "    return split_dir\n",
        "\n",
        "def prepare_dataset(cfg):\n",
        "    base_dir = cfg[\"BASE_DIR\"]\n",
        "    images_tar = os.path.join(base_dir, \"images.tar\")\n",
        "    lists_tar  = os.path.join(base_dir, \"lists.tar\")\n",
        "\n",
        "    download_if_not_exists(IMAGES_URL, images_tar)\n",
        "    download_if_not_exists(LISTS_URL, lists_tar)\n",
        "\n",
        "    if not os.path.exists(os.path.join(base_dir, \"Images\")):\n",
        "        extract_if_not_exists(images_tar, base_dir)\n",
        "    if not os.path.exists(os.path.join(base_dir, \"train_list.mat\")):\n",
        "        extract_if_not_exists(lists_tar, base_dir)\n",
        "\n",
        "    create_train_test_split(base_dir, cfg[\"SPLIT_FOLDER\"])\n",
        "\n",
        "prepare_dataset(CONFIG)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# DATASET LOADING\n",
        "# ==========================================\n",
        "SPLIT_DIR = os.path.join(CONFIG[\"BASE_DIR\"], CONFIG[\"SPLIT_FOLDER\"])\n",
        "\n",
        "train_ds_full = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_DIR, \"train\"),\n",
        "    image_size=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"]),\n",
        "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "    shuffle=True,\n",
        "    seed=CONFIG[\"SEED\"],\n",
        ")\n",
        "\n",
        "class_names = train_ds_full.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "val_batches = int(len(train_ds_full) * CONFIG[\"VAL_SPLIT\"])\n",
        "val_ds = train_ds_full.take(val_batches)\n",
        "train_ds = train_ds_full.skip(val_batches)\n",
        "\n",
        "test_ds = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_DIR, \"test\"),\n",
        "    image_size=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"]),\n",
        "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "val_ds   = val_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "test_ds  = test_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# CNN Variant A – Deeper Network\n",
        "# ONLY CHANGE: +1 Conv Block\n",
        "# ==========================================\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "def build_cnn_variant_a(input_shape, num_classes, cfg):\n",
        "    x_in = keras.Input(shape=input_shape)\n",
        "    x = layers.Rescaling(1./255)(x_in)\n",
        "    if cfg[\"AUGMENT\"]:\n",
        "        x = data_augmentation(x)\n",
        "\n",
        "    # Block 1\n",
        "    for f in [64, 128, 256, 512]:  # <-- EXTRA BLOCK (256)\n",
        "        x = layers.Conv2D(f, 3, padding=\"same\")(x)\n",
        "        if cfg[\"USE_BATCHNORM\"]:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(cfg[\"DROPOUT\"])(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(cfg[\"DROPOUT\"])(x)\n",
        "\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(x_in, out, name=cfg[\"ID\"])\n",
        "\n",
        "model = build_cnn_variant_a(\n",
        "    (CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"], 3),\n",
        "    num_classes,\n",
        "    CONFIG\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ==========================================\n",
        "# Compile & Train\n",
        "# ==========================================\n",
        "optimizer = keras.optimizers.Adam(learning_rate=CONFIG[\"LEARNING_RATE\"])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=CONFIG[\"EARLY_STOP_PATIENCE\"],\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=CONFIG[\"EPOCHS\"],\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "for x, y in test_ds:\n",
        "    p = model.predict(x, verbose=0)\n",
        "    y_true.extend(y.numpy())\n",
        "    y_pred.extend(np.argmax(p, axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Save results\n",
        "# ==========================================\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "model.save(\"results/CNN_VARIANT_A_DEEPER.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KfBlM1ySgO0P",
        "outputId": "8f52f92e-8a74-4dd1-de6a-385d73bbf5be"
      },
      "id": "KfBlM1ySgO0P",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Active CONFIG:\n",
            "  AUGMENT: True\n",
            "  AUTOTUNE: -1\n",
            "  BASE_DIR: /content/datasets/stanford_dogs\n",
            "  BATCH_SIZE: 32\n",
            "  DROPOUT: 0.3\n",
            "  EARLY_STOP: True\n",
            "  EARLY_STOP_PATIENCE: 5\n",
            "  EPOCHS: 20\n",
            "  ID: CNN_VARIANT_A_DEEPER\n",
            "  IMG_SIZE: 128\n",
            "  LEARNING_RATE: 0.001\n",
            "  OPTIMIZER: adam\n",
            "  SEED: 42\n",
            "  SPLIT_FOLDER: stanford_dogs_split\n",
            "  USE_BATCHNORM: True\n",
            "  VAL_SPLIT: 0.1\n",
            "Found 12000 files belonging to 120 classes.\n",
            "Found 8580 files belonging to 120 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_VARIANT_A_DEEPER\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_VARIANT_A_DEEPER\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling_1 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m30,840\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,840</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,716,984\u001b[0m (6.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,716,984</span> (6.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,715,064\u001b[0m (6.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,715,064</span> (6.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 97ms/step - accuracy: 0.0124 - loss: 4.8834 - val_accuracy: 0.0084 - val_loss: 4.8360\n",
            "Epoch 2/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 92ms/step - accuracy: 0.0121 - loss: 4.7356 - val_accuracy: 0.0118 - val_loss: 4.7320\n",
            "Epoch 3/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0185 - loss: 4.6765 - val_accuracy: 0.0253 - val_loss: 4.6191\n",
            "Epoch 4/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0229 - loss: 4.5848 - val_accuracy: 0.0211 - val_loss: 4.5448\n",
            "Epoch 5/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0255 - loss: 4.5028 - val_accuracy: 0.0372 - val_loss: 4.4909\n",
            "Epoch 6/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0315 - loss: 4.4481 - val_accuracy: 0.0329 - val_loss: 4.5037\n",
            "Epoch 7/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 93ms/step - accuracy: 0.0340 - loss: 4.4003 - val_accuracy: 0.0372 - val_loss: 4.3141\n",
            "Epoch 8/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0423 - loss: 4.3249 - val_accuracy: 0.0220 - val_loss: 4.8131\n",
            "Epoch 9/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 92ms/step - accuracy: 0.0400 - loss: 4.2843 - val_accuracy: 0.0405 - val_loss: 4.3338\n",
            "Epoch 10/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0446 - loss: 4.2443 - val_accuracy: 0.0389 - val_loss: 4.2995\n",
            "Epoch 11/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0506 - loss: 4.1913 - val_accuracy: 0.0287 - val_loss: 4.5121\n",
            "Epoch 12/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0508 - loss: 4.1694 - val_accuracy: 0.0439 - val_loss: 4.2637\n",
            "Epoch 13/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0556 - loss: 4.1380 - val_accuracy: 0.0439 - val_loss: 4.3021\n",
            "Epoch 14/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0552 - loss: 4.1073 - val_accuracy: 0.0642 - val_loss: 4.0852\n",
            "Epoch 15/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0623 - loss: 4.0643 - val_accuracy: 0.0279 - val_loss: 4.3748\n",
            "Epoch 16/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0619 - loss: 4.0474 - val_accuracy: 0.0515 - val_loss: 4.1869\n",
            "Epoch 17/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0725 - loss: 3.9898 - val_accuracy: 0.0726 - val_loss: 3.9967\n",
            "Epoch 18/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 92ms/step - accuracy: 0.0735 - loss: 3.9637 - val_accuracy: 0.0194 - val_loss: 4.6384\n",
            "Epoch 19/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.0736 - loss: 3.9416 - val_accuracy: 0.0389 - val_loss: 4.4787\n",
            "Epoch 20/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 92ms/step - accuracy: 0.0812 - loss: 3.9093 - val_accuracy: 0.0380 - val_loss: 4.6447\n",
            "Test Accuracy: 0.0685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   class_001     0.0000    0.0000    0.0000        52\n",
            "   class_002     0.0893    0.0588    0.0709        85\n",
            "   class_003     0.1613    0.1645    0.1629       152\n",
            "   class_004     0.0000    0.0000    0.0000        49\n",
            "   class_005     0.0000    0.0000    0.0000       114\n",
            "   class_006     0.2584    0.5227    0.3459        88\n",
            "   class_007     0.2326    0.1042    0.1439        96\n",
            "   class_008     0.1000    0.0139    0.0244        72\n",
            "   class_009     0.0238    0.0417    0.0303        72\n",
            "   class_010     0.0000    0.0000    0.0000       139\n",
            "   class_011     0.1429    0.0267    0.0449        75\n",
            "   class_012     0.0000    0.0000    0.0000        95\n",
            "   class_013     0.0000    0.0000    0.0000        87\n",
            "   class_014     0.0714    0.0141    0.0235        71\n",
            "   class_015     0.0000    0.0000    0.0000        59\n",
            "   class_016     0.0000    0.0000    0.0000        53\n",
            "   class_017     0.1538    0.2105    0.1778        57\n",
            "   class_018     0.0635    0.0833    0.0721        48\n",
            "   class_019     0.0156    0.0196    0.0174        51\n",
            "   class_020     0.0227    0.0085    0.0123       118\n",
            "   class_021     0.0000    0.0000    0.0000        82\n",
            "   class_022     0.0909    0.1149    0.1015        87\n",
            "   class_023     0.0645    0.0227    0.0336        88\n",
            "   class_024     0.0000    0.0000    0.0000        96\n",
            "   class_025     0.0577    0.0588    0.0583        51\n",
            "   class_026     0.0000    0.0000    0.0000       100\n",
            "   class_027     0.0000    0.0000    0.0000       132\n",
            "   class_028     0.0164    0.0167    0.0165        60\n",
            "   class_029     0.0000    0.0000    0.0000        55\n",
            "   class_030     0.0000    0.0000    0.0000        64\n",
            "   class_031     0.0769    0.0122    0.0211        82\n",
            "   class_032     0.0405    0.0417    0.0411        72\n",
            "   class_033     0.5000    0.0127    0.0247        79\n",
            "   class_034     0.0519    0.2899    0.0881        69\n",
            "   class_035     0.1000    0.2083    0.1351        72\n",
            "   class_036     0.0385    0.0471    0.0423        85\n",
            "   class_037     0.0000    0.0000    0.0000        64\n",
            "   class_038     0.2143    0.1053    0.1412        57\n",
            "   class_039     0.0000    0.0000    0.0000        97\n",
            "   class_040     0.0000    0.0000    0.0000       102\n",
            "   class_041     0.0000    0.0000    0.0000       102\n",
            "   class_042     0.1000    0.0515    0.0680        97\n",
            "   class_043     0.1020    0.0521    0.0690        96\n",
            "   class_044     0.0479    0.1000    0.0648        80\n",
            "   class_045     0.1299    0.1220    0.1258        82\n",
            "   class_046     0.0000    0.0000    0.0000        54\n",
            "   class_047     0.0909    0.0175    0.0294        57\n",
            "   class_048     0.0000    0.0000    0.0000        55\n",
            "   class_049     0.0488    0.0690    0.0571        58\n",
            "   class_050     0.0000    0.0000    0.0000       106\n",
            "   class_051     0.0000    0.0000    0.0000        83\n",
            "   class_052     0.0275    0.2679    0.0498        56\n",
            "   class_053     0.0000    0.0000    0.0000        69\n",
            "   class_054     0.0000    0.0000    0.0000        86\n",
            "   class_055     0.0645    0.0385    0.0482        52\n",
            "   class_056     0.0620    0.1569    0.0889        51\n",
            "   class_057     0.0159    0.0200    0.0177        50\n",
            "   class_058     0.0000    0.0000    0.0000        71\n",
            "   class_059     0.0307    0.1194    0.0488        67\n",
            "   class_060     0.0000    0.0000    0.0000        52\n",
            "   class_061     0.0149    0.0185    0.0165        54\n",
            "   class_062     0.0000    0.0000    0.0000        61\n",
            "   class_063     0.0619    0.5455    0.1111        55\n",
            "   class_064     0.2667    0.0755    0.1176        53\n",
            "   class_065     0.0000    0.0000    0.0000        52\n",
            "   class_066     0.1351    0.1000    0.1149        50\n",
            "   class_067     0.0947    0.1525    0.1169        59\n",
            "   class_068     0.0857    0.0600    0.0706        50\n",
            "   class_069     0.0000    0.0000    0.0000        59\n",
            "   class_070     0.0714    0.0588    0.0645        51\n",
            "   class_071     0.0532    0.4200    0.0944        50\n",
            "   class_072     0.0297    0.3200    0.0544        50\n",
            "   class_073     0.0520    0.3148    0.0892        54\n",
            "   class_074     0.1129    0.1400    0.1250        50\n",
            "   class_075     0.0370    0.0400    0.0385        50\n",
            "   class_076     0.0952    0.0769    0.0851        52\n",
            "   class_077     0.0000    0.0000    0.0000        53\n",
            "   class_078     0.0057    0.0185    0.0087        54\n",
            "   class_079     0.0294    0.0580    0.0390        69\n",
            "   class_080     0.0610    0.0877    0.0719        57\n",
            "   class_081     0.0000    0.0000    0.0000        53\n",
            "   class_082     0.0637    0.2000    0.0966        50\n",
            "   class_083     0.1250    0.0600    0.0811        50\n",
            "   class_084     0.1366    0.4231    0.2066        52\n",
            "   class_085     0.2500    0.0385    0.0667        52\n",
            "   class_086     0.0565    0.2000    0.0881        50\n",
            "   class_087     0.1111    0.0119    0.0215        84\n",
            "   class_088     0.0385    0.0147    0.0213        68\n",
            "   class_089     0.2188    0.1186    0.1538       118\n",
            "   class_090     0.0876    0.2353    0.1277        51\n",
            "   class_091     0.3714    0.3824    0.3768       102\n",
            "   class_092     0.0000    0.0000    0.0000        51\n",
            "   class_093     0.0000    0.0000    0.0000        56\n",
            "   class_094     0.2222    0.0385    0.0656        52\n",
            "   class_095     0.0000    0.0000    0.0000        59\n",
            "   class_096     0.0000    0.0000    0.0000        56\n",
            "   class_097     0.1754    0.1429    0.1575        70\n",
            "   class_098     0.0000    0.0000    0.0000        50\n",
            "   class_099     0.2000    0.0385    0.0645        78\n",
            "   class_100     0.0000    0.0000    0.0000        92\n",
            "   class_101     0.1667    0.0800    0.1081        50\n",
            "   class_102     0.0915    0.1193    0.1036       109\n",
            "   class_103     0.0000    0.0000    0.0000       100\n",
            "   class_104     0.1463    0.0545    0.0795       110\n",
            "   class_105     0.0000    0.0000    0.0000        95\n",
            "   class_106     0.0000    0.0000    0.0000       113\n",
            "   class_107     0.0000    0.0000    0.0000       118\n",
            "   class_108     0.0345    0.0756    0.0474       119\n",
            "   class_109     0.1250    0.0104    0.0192        96\n",
            "   class_110     0.0566    0.1552    0.0829        58\n",
            "   class_111     0.0517    0.1132    0.0710        53\n",
            "   class_112     0.1053    0.1235    0.1136        81\n",
            "   class_113     0.0000    0.0000    0.0000        55\n",
            "   class_114     0.0143    0.0588    0.0230        51\n",
            "   class_115     0.0000    0.0000    0.0000        55\n",
            "   class_116     0.0000    0.0000    0.0000        59\n",
            "   class_117     0.0473    0.1455    0.0714        55\n",
            "   class_118     0.0000    0.0000    0.0000        56\n",
            "   class_119     0.0394    0.1000    0.0565        50\n",
            "   class_120     0.5000    0.1304    0.2069        69\n",
            "\n",
            "    accuracy                         0.0685      8580\n",
            "   macro avg     0.0662    0.0731    0.0519      8580\n",
            "weighted avg     0.0680    0.0685    0.0523      8580\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}