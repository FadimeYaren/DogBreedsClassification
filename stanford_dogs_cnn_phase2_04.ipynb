{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Imports & Environment\n",
        "# =========================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "from scipy.io import loadmat\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# ==========================================\n",
        "# CONFIG (Baseline ile AYNI)\n",
        "# ==========================================\n",
        "BASE_CONFIG = {\n",
        "    \"BASE_DIR\": \"/content/datasets/stanford_dogs\",\n",
        "    \"SPLIT_FOLDER\": \"stanford_dogs_split\",\n",
        "\n",
        "    \"IMG_SIZE\": 128,\n",
        "    \"VAL_SPLIT\": 0.1,\n",
        "    \"AUTOTUNE\": tf.data.AUTOTUNE,\n",
        "\n",
        "    \"EPOCHS\": 20,\n",
        "    \"EARLY_STOP\": True,\n",
        "    \"EARLY_STOP_PATIENCE\": 5,\n",
        "\n",
        "    \"SEED\": 42,\n",
        "}\n",
        "\n",
        "CNN_CONFIG = {\n",
        "    \"ID\": \"CNN_VARIANT_A_DEEPER\",\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"LEARNING_RATE\": 1e-3,\n",
        "    \"OPTIMIZER\": \"adam\",\n",
        "    \"DROPOUT\": 0.3,\n",
        "    \"USE_BATCHNORM\": True,\n",
        "    \"AUGMENT\": True,\n",
        "}\n",
        "\n",
        "CONFIG = BASE_CONFIG.copy()\n",
        "CONFIG.update(CNN_CONFIG)\n",
        "\n",
        "os.makedirs(CONFIG[\"BASE_DIR\"], exist_ok=True)\n",
        "\n",
        "SEED = CONFIG[\"SEED\"]\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"Active CONFIG:\")\n",
        "for k in sorted(CONFIG.keys()):\n",
        "    print(f\"  {k}: {CONFIG[k]}\")\n",
        "\n",
        "# ==========================================\n",
        "# DATASET PREPARATION (same logic)\n",
        "# ==========================================\n",
        "IMAGES_URL = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
        "LISTS_URL  = \"http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\"\n",
        "\n",
        "def download_if_not_exists(url, dest_path):\n",
        "    if os.path.exists(dest_path):\n",
        "        return\n",
        "    urllib.request.urlretrieve(url, dest_path)\n",
        "\n",
        "def extract_if_not_exists(tar_path, extract_to):\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    with tarfile.open(tar_path) as tar:\n",
        "        tar.extractall(extract_to)\n",
        "\n",
        "def create_train_test_split(base_dir, split_folder):\n",
        "    split_dir = os.path.join(base_dir, split_folder)\n",
        "    if os.path.exists(split_dir):\n",
        "        return split_dir\n",
        "\n",
        "    images_dir = os.path.join(base_dir, \"Images\")\n",
        "    train_mat_path = os.path.join(base_dir, \"train_list.mat\")\n",
        "    test_mat_path  = os.path.join(base_dir, \"test_list.mat\")\n",
        "\n",
        "    os.makedirs(split_dir, exist_ok=True)\n",
        "    train_root = os.path.join(split_dir, \"train\")\n",
        "    test_root  = os.path.join(split_dir, \"test\")\n",
        "    os.makedirs(train_root, exist_ok=True)\n",
        "    os.makedirs(test_root, exist_ok=True)\n",
        "\n",
        "    train_mat = loadmat(train_mat_path)\n",
        "    test_mat  = loadmat(test_mat_path)\n",
        "\n",
        "    def mat_to_list(mat):\n",
        "        out = []\n",
        "        for i in range(mat.shape[0]):\n",
        "            x = mat[i][0]\n",
        "            while isinstance(x, np.ndarray):\n",
        "                x = x[0]\n",
        "            out.append(str(x))\n",
        "        return out\n",
        "\n",
        "    train_files = mat_to_list(train_mat[\"file_list\"])\n",
        "    train_labels = train_mat[\"labels\"].reshape(-1)\n",
        "    test_files = mat_to_list(test_mat[\"file_list\"])\n",
        "    test_labels = test_mat[\"labels\"].reshape(-1)\n",
        "\n",
        "    for p, l in zip(train_files, train_labels):\n",
        "        c = f\"class_{int(l):03d}\"\n",
        "        os.makedirs(os.path.join(train_root, c), exist_ok=True)\n",
        "        shutil.copy(os.path.join(images_dir, p), os.path.join(train_root, c, os.path.basename(p)))\n",
        "\n",
        "    for p, l in zip(test_files, test_labels):\n",
        "        c = f\"class_{int(l):03d}\"\n",
        "        os.makedirs(os.path.join(test_root, c), exist_ok=True)\n",
        "        shutil.copy(os.path.join(images_dir, p), os.path.join(test_root, c, os.path.basename(p)))\n",
        "\n",
        "    return split_dir\n",
        "\n",
        "def prepare_dataset(cfg):\n",
        "    base_dir = cfg[\"BASE_DIR\"]\n",
        "    images_tar = os.path.join(base_dir, \"images.tar\")\n",
        "    lists_tar  = os.path.join(base_dir, \"lists.tar\")\n",
        "\n",
        "    download_if_not_exists(IMAGES_URL, images_tar)\n",
        "    download_if_not_exists(LISTS_URL, lists_tar)\n",
        "\n",
        "    if not os.path.exists(os.path.join(base_dir, \"Images\")):\n",
        "        extract_if_not_exists(images_tar, base_dir)\n",
        "    if not os.path.exists(os.path.join(base_dir, \"train_list.mat\")):\n",
        "        extract_if_not_exists(lists_tar, base_dir)\n",
        "\n",
        "    create_train_test_split(base_dir, cfg[\"SPLIT_FOLDER\"])\n",
        "\n",
        "prepare_dataset(CONFIG)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# DATASET LOADING\n",
        "# ==========================================\n",
        "SPLIT_DIR = os.path.join(CONFIG[\"BASE_DIR\"], CONFIG[\"SPLIT_FOLDER\"])\n",
        "\n",
        "train_ds_full = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_DIR, \"train\"),\n",
        "    image_size=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"]),\n",
        "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "    shuffle=True,\n",
        "    seed=CONFIG[\"SEED\"],\n",
        ")\n",
        "\n",
        "class_names = train_ds_full.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "val_batches = int(len(train_ds_full) * CONFIG[\"VAL_SPLIT\"])\n",
        "val_ds = train_ds_full.take(val_batches)\n",
        "train_ds = train_ds_full.skip(val_batches)\n",
        "\n",
        "test_ds = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_DIR, \"test\"),\n",
        "    image_size=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"]),\n",
        "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "val_ds   = val_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "test_ds  = test_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# CNN Variant A – Deeper Network\n",
        "# ONLY CHANGE: +1 Conv Block\n",
        "# ==========================================\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "def build_cnn_variant_a(input_shape, num_classes, cfg):\n",
        "    x_in = keras.Input(shape=input_shape)\n",
        "    x = layers.Rescaling(1./255)(x_in)\n",
        "    if cfg[\"AUGMENT\"]:\n",
        "        x = data_augmentation(x)\n",
        "\n",
        "    # Block 1\n",
        "    for f in [32, 64, 128, 256]:  # <-- EXTRA BLOCK (256)\n",
        "        x = layers.Conv2D(f, 5, padding=\"same\")(x)\n",
        "        if cfg[\"USE_BATCHNORM\"]:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(cfg[\"DROPOUT\"])(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(cfg[\"DROPOUT\"])(x)\n",
        "\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(x_in, out, name=cfg[\"ID\"])\n",
        "\n",
        "model = build_cnn_variant_a(\n",
        "    (CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"], 3),\n",
        "    num_classes,\n",
        "    CONFIG\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ==========================================\n",
        "# Compile & Train\n",
        "# ==========================================\n",
        "optimizer = keras.optimizers.Adam(learning_rate=CONFIG[\"LEARNING_RATE\"])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=CONFIG[\"EARLY_STOP_PATIENCE\"],\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=CONFIG[\"EPOCHS\"],\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "for x, y in test_ds:\n",
        "    p = model.predict(x, verbose=0)\n",
        "    y_true.extend(y.numpy())\n",
        "    y_pred.extend(np.argmax(p, axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Save results\n",
        "# ==========================================\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "model.save(\"results/CNN_VARIANT_A_DEEPER.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KfBlM1ySgO0P",
        "outputId": "fb0443bf-ae94-43dd-83fd-8675a21c7617"
      },
      "id": "KfBlM1ySgO0P",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Active CONFIG:\n",
            "  AUGMENT: True\n",
            "  AUTOTUNE: -1\n",
            "  BASE_DIR: /content/datasets/stanford_dogs\n",
            "  BATCH_SIZE: 32\n",
            "  DROPOUT: 0.3\n",
            "  EARLY_STOP: True\n",
            "  EARLY_STOP_PATIENCE: 5\n",
            "  EPOCHS: 20\n",
            "  ID: CNN_VARIANT_A_DEEPER\n",
            "  IMG_SIZE: 128\n",
            "  LEARNING_RATE: 0.001\n",
            "  OPTIMIZER: adam\n",
            "  SEED: 42\n",
            "  SPLIT_FOLDER: stanford_dogs_split\n",
            "  USE_BATCHNORM: True\n",
            "  VAL_SPLIT: 0.1\n",
            "Found 12000 files belonging to 120 classes.\n",
            "Found 8580 files belonging to 120 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_VARIANT_A_DEEPER\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_VARIANT_A_DEEPER\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m2,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m51,264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m204,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m819,456\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m30,840\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,840</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,176,632\u001b[0m (4.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,176,632</span> (4.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,175,672\u001b[0m (4.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,175,672</span> (4.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 74ms/step - accuracy: 0.0096 - loss: 4.8713 - val_accuracy: 0.0093 - val_loss: 4.8678\n",
            "Epoch 2/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.0172 - loss: 4.7137 - val_accuracy: 0.0135 - val_loss: 5.1873\n",
            "Epoch 3/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.0190 - loss: 4.6440 - val_accuracy: 0.0127 - val_loss: 4.7992\n",
            "Epoch 4/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.0249 - loss: 4.5627 - val_accuracy: 0.0177 - val_loss: 4.6512\n",
            "Epoch 5/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.0322 - loss: 4.4485 - val_accuracy: 0.0321 - val_loss: 4.4412\n",
            "Epoch 6/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.0436 - loss: 4.3459 - val_accuracy: 0.0270 - val_loss: 4.4148\n",
            "Epoch 7/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.0472 - loss: 4.2657 - val_accuracy: 0.0296 - val_loss: 4.4017\n",
            "Epoch 8/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.0561 - loss: 4.1877 - val_accuracy: 0.0312 - val_loss: 4.3790\n",
            "Epoch 9/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.0602 - loss: 4.1340 - val_accuracy: 0.0355 - val_loss: 4.3552\n",
            "Epoch 10/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 62ms/step - accuracy: 0.0713 - loss: 4.0671 - val_accuracy: 0.0465 - val_loss: 4.3108\n",
            "Epoch 11/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.0669 - loss: 4.0251 - val_accuracy: 0.0591 - val_loss: 4.1927\n",
            "Epoch 12/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.0794 - loss: 3.9683 - val_accuracy: 0.0431 - val_loss: 4.4290\n",
            "Epoch 13/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 62ms/step - accuracy: 0.0826 - loss: 3.9064 - val_accuracy: 0.0853 - val_loss: 3.9400\n",
            "Epoch 14/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.0882 - loss: 3.8667 - val_accuracy: 0.0676 - val_loss: 4.1532\n",
            "Epoch 15/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.1003 - loss: 3.8134 - val_accuracy: 0.0709 - val_loss: 4.0319\n",
            "Epoch 16/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.0995 - loss: 3.7774 - val_accuracy: 0.0785 - val_loss: 4.1559\n",
            "Epoch 17/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.1015 - loss: 3.7399 - val_accuracy: 0.0684 - val_loss: 4.0698\n",
            "Epoch 18/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.1108 - loss: 3.6909 - val_accuracy: 0.0819 - val_loss: 3.9881\n",
            "Test Accuracy: 0.0802\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   class_001     0.0000    0.0000    0.0000        52\n",
            "   class_002     0.1076    0.3647    0.1662        85\n",
            "   class_003     0.3235    0.0724    0.1183       152\n",
            "   class_004     0.0000    0.0000    0.0000        49\n",
            "   class_005     0.0000    0.0000    0.0000       114\n",
            "   class_006     0.1523    0.3409    0.2105        88\n",
            "   class_007     0.0545    0.0312    0.0397        96\n",
            "   class_008     0.0000    0.0000    0.0000        72\n",
            "   class_009     0.0287    0.0972    0.0443        72\n",
            "   class_010     0.0811    0.0216    0.0341       139\n",
            "   class_011     0.0610    0.0667    0.0637        75\n",
            "   class_012     0.0000    0.0000    0.0000        95\n",
            "   class_013     0.1000    0.0345    0.0513        87\n",
            "   class_014     0.1667    0.0563    0.0842        71\n",
            "   class_015     0.0000    0.0000    0.0000        59\n",
            "   class_016     0.1333    0.0755    0.0964        53\n",
            "   class_017     0.1144    0.4035    0.1783        57\n",
            "   class_018     0.0833    0.0417    0.0556        48\n",
            "   class_019     0.0189    0.0196    0.0192        51\n",
            "   class_020     0.0833    0.0424    0.0562       118\n",
            "   class_021     0.3333    0.0122    0.0235        82\n",
            "   class_022     0.0792    0.0920    0.0851        87\n",
            "   class_023     0.2857    0.0227    0.0421        88\n",
            "   class_024     0.1250    0.0104    0.0192        96\n",
            "   class_025     0.0750    0.1176    0.0916        51\n",
            "   class_026     0.0000    0.0000    0.0000       100\n",
            "   class_027     0.3125    0.0758    0.1220       132\n",
            "   class_028     0.0400    0.0333    0.0364        60\n",
            "   class_029     0.0833    0.0727    0.0777        55\n",
            "   class_030     0.0000    0.0000    0.0000        64\n",
            "   class_031     0.0000    0.0000    0.0000        82\n",
            "   class_032     0.0541    0.0556    0.0548        72\n",
            "   class_033     0.2000    0.0127    0.0238        79\n",
            "   class_034     0.0556    0.0145    0.0230        69\n",
            "   class_035     0.0000    0.0000    0.0000        72\n",
            "   class_036     0.0000    0.0000    0.0000        85\n",
            "   class_037     0.0000    0.0000    0.0000        64\n",
            "   class_038     0.0652    0.0526    0.0583        57\n",
            "   class_039     0.2857    0.0206    0.0385        97\n",
            "   class_040     0.1538    0.1961    0.1724       102\n",
            "   class_041     0.0000    0.0000    0.0000       102\n",
            "   class_042     0.0769    0.0103    0.0182        97\n",
            "   class_043     0.0625    0.0312    0.0417        96\n",
            "   class_044     0.0696    0.1000    0.0821        80\n",
            "   class_045     0.0814    0.3415    0.1315        82\n",
            "   class_046     0.0000    0.0000    0.0000        54\n",
            "   class_047     0.0000    0.0000    0.0000        57\n",
            "   class_048     0.5000    0.0182    0.0351        55\n",
            "   class_049     0.0357    0.0172    0.0233        58\n",
            "   class_050     0.0000    0.0000    0.0000       106\n",
            "   class_051     0.0000    0.0000    0.0000        83\n",
            "   class_052     0.1053    0.1071    0.1062        56\n",
            "   class_053     0.1273    0.1014    0.1129        69\n",
            "   class_054     0.0909    0.0116    0.0206        86\n",
            "   class_055     0.0588    0.0192    0.0290        52\n",
            "   class_056     0.0442    0.1569    0.0690        51\n",
            "   class_057     0.1250    0.0200    0.0345        50\n",
            "   class_058     0.0000    0.0000    0.0000        71\n",
            "   class_059     0.0909    0.0149    0.0256        67\n",
            "   class_060     0.0000    0.0000    0.0000        52\n",
            "   class_061     0.0000    0.0000    0.0000        54\n",
            "   class_062     0.0000    0.0000    0.0000        61\n",
            "   class_063     0.0483    0.2364    0.0802        55\n",
            "   class_064     0.0980    0.0943    0.0962        53\n",
            "   class_065     0.0000    0.0000    0.0000        52\n",
            "   class_066     0.0811    0.1200    0.0968        50\n",
            "   class_067     0.0533    0.0678    0.0597        59\n",
            "   class_068     0.0000    0.0000    0.0000        50\n",
            "   class_069     0.0000    0.0000    0.0000        59\n",
            "   class_070     0.0475    0.3333    0.0831        51\n",
            "   class_071     0.1026    0.6200    0.1761        50\n",
            "   class_072     0.0460    0.3200    0.0804        50\n",
            "   class_073     0.0477    0.3889    0.0850        54\n",
            "   class_074     0.0806    0.1000    0.0893        50\n",
            "   class_075     0.0120    0.0200    0.0150        50\n",
            "   class_076     0.0000    0.0000    0.0000        52\n",
            "   class_077     0.0275    0.0566    0.0370        53\n",
            "   class_078     0.1055    0.5000    0.1742        54\n",
            "   class_079     0.0741    0.0870    0.0800        69\n",
            "   class_080     0.0164    0.0175    0.0169        57\n",
            "   class_081     0.5000    0.0189    0.0364        53\n",
            "   class_082     0.0507    0.2800    0.0859        50\n",
            "   class_083     0.0541    0.0400    0.0460        50\n",
            "   class_084     0.0930    0.4615    0.1548        52\n",
            "   class_085     0.1026    0.0769    0.0879        52\n",
            "   class_086     0.0217    0.0400    0.0282        50\n",
            "   class_087     0.0588    0.0357    0.0444        84\n",
            "   class_088     0.0192    0.0147    0.0167        68\n",
            "   class_089     0.2109    0.2288    0.2195       118\n",
            "   class_090     0.0483    0.1373    0.0714        51\n",
            "   class_091     0.1679    0.4608    0.2461       102\n",
            "   class_092     0.0000    0.0000    0.0000        51\n",
            "   class_093     0.0000    0.0000    0.0000        56\n",
            "   class_094     0.2500    0.0577    0.0938        52\n",
            "   class_095     0.0000    0.0000    0.0000        59\n",
            "   class_096     0.0000    0.0000    0.0000        56\n",
            "   class_097     0.1376    0.3714    0.2008        70\n",
            "   class_098     0.0256    0.0200    0.0225        50\n",
            "   class_099     0.0645    0.0513    0.0571        78\n",
            "   class_100     0.0882    0.0326    0.0476        92\n",
            "   class_101     0.0625    0.0200    0.0303        50\n",
            "   class_102     0.1111    0.1835    0.1384       109\n",
            "   class_103     0.0000    0.0000    0.0000       100\n",
            "   class_104     0.0545    0.0545    0.0545       110\n",
            "   class_105     0.0625    0.0105    0.0180        95\n",
            "   class_106     0.1270    0.0708    0.0909       113\n",
            "   class_107     0.0000    0.0000    0.0000       118\n",
            "   class_108     0.1000    0.0168    0.0288       119\n",
            "   class_109     0.2500    0.0104    0.0200        96\n",
            "   class_110     0.1324    0.1552    0.1429        58\n",
            "   class_111     0.0544    0.2453    0.0890        53\n",
            "   class_112     0.0164    0.0123    0.0141        81\n",
            "   class_113     0.0588    0.0182    0.0278        55\n",
            "   class_114     0.0508    0.0588    0.0545        51\n",
            "   class_115     0.0455    0.0182    0.0260        55\n",
            "   class_116     0.0000    0.0000    0.0000        59\n",
            "   class_117     0.0537    0.2364    0.0875        55\n",
            "   class_118     0.2500    0.0179    0.0333        56\n",
            "   class_119     0.0909    0.2000    0.1250        50\n",
            "   class_120     0.2759    0.1159    0.1633        69\n",
            "\n",
            "    accuracy                         0.0802      8580\n",
            "   macro avg     0.0805    0.0845    0.0549      8580\n",
            "weighted avg     0.0871    0.0802    0.0566      8580\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}