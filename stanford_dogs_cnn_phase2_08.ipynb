{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Imports & Environment\n",
        "# =========================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "from scipy.io import loadmat\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# ==========================================\n",
        "# CONFIG (Baseline ile AYNI)\n",
        "# ==========================================\n",
        "BASE_CONFIG = {\n",
        "    \"BASE_DIR\": \"/content/datasets/stanford_dogs\",\n",
        "    \"SPLIT_FOLDER\": \"stanford_dogs_split\",\n",
        "\n",
        "    \"IMG_SIZE\": 128,\n",
        "    \"VAL_SPLIT\": 0.1,\n",
        "    \"AUTOTUNE\": tf.data.AUTOTUNE,\n",
        "\n",
        "    \"EPOCHS\": 20,\n",
        "    \"EARLY_STOP\": True,\n",
        "    \"EARLY_STOP_PATIENCE\": 5,\n",
        "\n",
        "    \"SEED\": 42,\n",
        "}\n",
        "\n",
        "CNN_CONFIG = {\n",
        "    \"ID\": \"CNN_VARIANT_A_DEEPER\",\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"LEARNING_RATE\": 1e-3,\n",
        "    \"OPTIMIZER\": \"adam\",\n",
        "    \"DROPOUT\": 0.3,\n",
        "    \"USE_BATCHNORM\": True,\n",
        "    \"AUGMENT\": True,\n",
        "}\n",
        "\n",
        "CONFIG = BASE_CONFIG.copy()\n",
        "CONFIG.update(CNN_CONFIG)\n",
        "\n",
        "os.makedirs(CONFIG[\"BASE_DIR\"], exist_ok=True)\n",
        "\n",
        "SEED = CONFIG[\"SEED\"]\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"Active CONFIG:\")\n",
        "for k in sorted(CONFIG.keys()):\n",
        "    print(f\"  {k}: {CONFIG[k]}\")\n",
        "\n",
        "# ==========================================\n",
        "# DATASET PREPARATION (same logic)\n",
        "# ==========================================\n",
        "IMAGES_URL = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
        "LISTS_URL  = \"http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\"\n",
        "\n",
        "def download_if_not_exists(url, dest_path):\n",
        "    if os.path.exists(dest_path):\n",
        "        return\n",
        "    urllib.request.urlretrieve(url, dest_path)\n",
        "\n",
        "def extract_if_not_exists(tar_path, extract_to):\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    with tarfile.open(tar_path) as tar:\n",
        "        tar.extractall(extract_to)\n",
        "\n",
        "def create_train_test_split(base_dir, split_folder):\n",
        "    split_dir = os.path.join(base_dir, split_folder)\n",
        "    if os.path.exists(split_dir):\n",
        "        return split_dir\n",
        "\n",
        "    images_dir = os.path.join(base_dir, \"Images\")\n",
        "    train_mat_path = os.path.join(base_dir, \"train_list.mat\")\n",
        "    test_mat_path  = os.path.join(base_dir, \"test_list.mat\")\n",
        "\n",
        "    os.makedirs(split_dir, exist_ok=True)\n",
        "    train_root = os.path.join(split_dir, \"train\")\n",
        "    test_root  = os.path.join(split_dir, \"test\")\n",
        "    os.makedirs(train_root, exist_ok=True)\n",
        "    os.makedirs(test_root, exist_ok=True)\n",
        "\n",
        "    train_mat = loadmat(train_mat_path)\n",
        "    test_mat  = loadmat(test_mat_path)\n",
        "\n",
        "    def mat_to_list(mat):\n",
        "        out = []\n",
        "        for i in range(mat.shape[0]):\n",
        "            x = mat[i][0]\n",
        "            while isinstance(x, np.ndarray):\n",
        "                x = x[0]\n",
        "            out.append(str(x))\n",
        "        return out\n",
        "\n",
        "    train_files = mat_to_list(train_mat[\"file_list\"])\n",
        "    train_labels = train_mat[\"labels\"].reshape(-1)\n",
        "    test_files = mat_to_list(test_mat[\"file_list\"])\n",
        "    test_labels = test_mat[\"labels\"].reshape(-1)\n",
        "\n",
        "    for p, l in zip(train_files, train_labels):\n",
        "        c = f\"class_{int(l):03d}\"\n",
        "        os.makedirs(os.path.join(train_root, c), exist_ok=True)\n",
        "        shutil.copy(os.path.join(images_dir, p), os.path.join(train_root, c, os.path.basename(p)))\n",
        "\n",
        "    for p, l in zip(test_files, test_labels):\n",
        "        c = f\"class_{int(l):03d}\"\n",
        "        os.makedirs(os.path.join(test_root, c), exist_ok=True)\n",
        "        shutil.copy(os.path.join(images_dir, p), os.path.join(test_root, c, os.path.basename(p)))\n",
        "\n",
        "    return split_dir\n",
        "\n",
        "def prepare_dataset(cfg):\n",
        "    base_dir = cfg[\"BASE_DIR\"]\n",
        "    images_tar = os.path.join(base_dir, \"images.tar\")\n",
        "    lists_tar  = os.path.join(base_dir, \"lists.tar\")\n",
        "\n",
        "    download_if_not_exists(IMAGES_URL, images_tar)\n",
        "    download_if_not_exists(LISTS_URL, lists_tar)\n",
        "\n",
        "    if not os.path.exists(os.path.join(base_dir, \"Images\")):\n",
        "        extract_if_not_exists(images_tar, base_dir)\n",
        "    if not os.path.exists(os.path.join(base_dir, \"train_list.mat\")):\n",
        "        extract_if_not_exists(lists_tar, base_dir)\n",
        "\n",
        "    create_train_test_split(base_dir, cfg[\"SPLIT_FOLDER\"])\n",
        "\n",
        "prepare_dataset(CONFIG)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# DATASET LOADING\n",
        "# ==========================================\n",
        "SPLIT_DIR = os.path.join(CONFIG[\"BASE_DIR\"], CONFIG[\"SPLIT_FOLDER\"])\n",
        "\n",
        "train_ds_full = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_DIR, \"train\"),\n",
        "    image_size=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"]),\n",
        "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "    shuffle=True,\n",
        "    seed=CONFIG[\"SEED\"],\n",
        ")\n",
        "\n",
        "class_names = train_ds_full.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "val_batches = int(len(train_ds_full) * CONFIG[\"VAL_SPLIT\"])\n",
        "val_ds = train_ds_full.take(val_batches)\n",
        "train_ds = train_ds_full.skip(val_batches)\n",
        "\n",
        "test_ds = keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_DIR, \"test\"),\n",
        "    image_size=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"]),\n",
        "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "val_ds   = val_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "test_ds  = test_ds.cache().prefetch(CONFIG[\"AUTOTUNE\"])\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# CNN Variant A – Deeper Network\n",
        "# ONLY CHANGE: +1 Conv Block\n",
        "# ==========================================\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "def build_cnn_variant_a(input_shape, num_classes, cfg):\n",
        "    x_in = keras.Input(shape=input_shape)\n",
        "    x = layers.Rescaling(1./255)(x_in)\n",
        "    if cfg[\"AUGMENT\"]:\n",
        "        x = data_augmentation(x)\n",
        "\n",
        "    # Block 1\n",
        "    for f in [32, 64, 128, 256]:  # <-- EXTRA BLOCK (256)\n",
        "        x = layers.Conv2D(f, 3, padding=\"same\")(x)\n",
        "        if cfg[\"USE_BATCHNORM\"]:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"elu\")(x)\n",
        "        x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(cfg[\"DROPOUT\"])(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(cfg[\"DROPOUT\"])(x)\n",
        "\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(x_in, out, name=cfg[\"ID\"])\n",
        "\n",
        "model = build_cnn_variant_a(\n",
        "    (CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"], 3),\n",
        "    num_classes,\n",
        "    CONFIG\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ==========================================\n",
        "# Compile & Train\n",
        "# ==========================================\n",
        "optimizer = keras.optimizers.Adam(learning_rate=CONFIG[\"LEARNING_RATE\"])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=CONFIG[\"EARLY_STOP_PATIENCE\"],\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=CONFIG[\"EPOCHS\"],\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "for x, y in test_ds:\n",
        "    p = model.predict(x, verbose=0)\n",
        "    y_true.extend(y.numpy())\n",
        "    y_pred.extend(np.argmax(p, axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Save results\n",
        "# ==========================================\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "model.save(\"results/CNN_VARIANT_A_DEEPER.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KfBlM1ySgO0P",
        "outputId": "dc460733-ce9b-47c5-dc0f-45fe06a91c85"
      },
      "id": "KfBlM1ySgO0P",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Active CONFIG:\n",
            "  AUGMENT: True\n",
            "  AUTOTUNE: -1\n",
            "  BASE_DIR: /content/datasets/stanford_dogs\n",
            "  BATCH_SIZE: 32\n",
            "  DROPOUT: 0.3\n",
            "  EARLY_STOP: True\n",
            "  EARLY_STOP_PATIENCE: 5\n",
            "  EPOCHS: 20\n",
            "  ID: CNN_VARIANT_A_DEEPER\n",
            "  IMG_SIZE: 128\n",
            "  LEARNING_RATE: 0.001\n",
            "  OPTIMIZER: adam\n",
            "  SEED: 42\n",
            "  SPLIT_FOLDER: stanford_dogs_split\n",
            "  USE_BATCHNORM: True\n",
            "  VAL_SPLIT: 0.1\n",
            "Found 12000 files belonging to 120 classes.\n",
            "Found 8580 files belonging to 120 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_VARIANT_A_DEEPER\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_VARIANT_A_DEEPER\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m30,840\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,840</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m486,968\u001b[0m (1.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">486,968</span> (1.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m486,008\u001b[0m (1.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">486,008</span> (1.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - accuracy: 0.0110 - loss: 4.8923 - val_accuracy: 0.0084 - val_loss: 4.7647\n",
            "Epoch 2/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - accuracy: 0.0131 - loss: 4.7453 - val_accuracy: 0.0144 - val_loss: 4.7835\n",
            "Epoch 3/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.0160 - loss: 4.6906 - val_accuracy: 0.0084 - val_loss: 4.8072\n",
            "Epoch 4/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - accuracy: 0.0206 - loss: 4.6385 - val_accuracy: 0.0177 - val_loss: 4.6717\n",
            "Epoch 5/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0252 - loss: 4.5694 - val_accuracy: 0.0127 - val_loss: 4.7136\n",
            "Epoch 6/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - accuracy: 0.0315 - loss: 4.5064 - val_accuracy: 0.0220 - val_loss: 4.6065\n",
            "Epoch 7/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0341 - loss: 4.4512 - val_accuracy: 0.0270 - val_loss: 4.5078\n",
            "Epoch 8/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.0415 - loss: 4.3893 - val_accuracy: 0.0304 - val_loss: 4.5100\n",
            "Epoch 9/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0416 - loss: 4.3486 - val_accuracy: 0.0380 - val_loss: 4.4947\n",
            "Epoch 10/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - accuracy: 0.0539 - loss: 4.3110 - val_accuracy: 0.0329 - val_loss: 4.5609\n",
            "Epoch 11/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - accuracy: 0.0553 - loss: 4.2570 - val_accuracy: 0.0220 - val_loss: 4.6869\n",
            "Epoch 12/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0603 - loss: 4.2217 - val_accuracy: 0.0270 - val_loss: 4.6406\n",
            "Epoch 13/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - accuracy: 0.0580 - loss: 4.1894 - val_accuracy: 0.0465 - val_loss: 4.3334\n",
            "Epoch 14/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0642 - loss: 4.1508 - val_accuracy: 0.0473 - val_loss: 4.3037\n",
            "Epoch 15/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - accuracy: 0.0666 - loss: 4.1297 - val_accuracy: 0.0481 - val_loss: 4.4007\n",
            "Epoch 16/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0754 - loss: 4.0741 - val_accuracy: 0.0448 - val_loss: 4.3312\n",
            "Epoch 17/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0745 - loss: 4.0551 - val_accuracy: 0.0481 - val_loss: 4.3705\n",
            "Epoch 18/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0749 - loss: 4.0296 - val_accuracy: 0.0524 - val_loss: 4.2865\n",
            "Epoch 19/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.0831 - loss: 4.0044 - val_accuracy: 0.0507 - val_loss: 4.3574\n",
            "Epoch 20/20\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.0859 - loss: 3.9834 - val_accuracy: 0.0591 - val_loss: 4.3153\n",
            "Test Accuracy: 0.0541\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   class_001     0.0000    0.0000    0.0000        52\n",
            "   class_002     0.1127    0.0941    0.1026        85\n",
            "   class_003     0.0625    0.0132    0.0217       152\n",
            "   class_004     0.0000    0.0000    0.0000        49\n",
            "   class_005     0.0000    0.0000    0.0000       114\n",
            "   class_006     0.0889    0.5909    0.1545        88\n",
            "   class_007     0.4545    0.0521    0.0935        96\n",
            "   class_008     0.0000    0.0000    0.0000        72\n",
            "   class_009     0.1818    0.0278    0.0482        72\n",
            "   class_010     0.0000    0.0000    0.0000       139\n",
            "   class_011     0.1020    0.0667    0.0806        75\n",
            "   class_012     0.0303    0.0105    0.0156        95\n",
            "   class_013     0.0588    0.0230    0.0331        87\n",
            "   class_014     0.0000    0.0000    0.0000        71\n",
            "   class_015     0.0000    0.0000    0.0000        59\n",
            "   class_016     0.2500    0.0189    0.0351        53\n",
            "   class_017     0.1667    0.0526    0.0800        57\n",
            "   class_018     0.0152    0.0208    0.0175        48\n",
            "   class_019     0.0000    0.0000    0.0000        51\n",
            "   class_020     0.2500    0.0085    0.0164       118\n",
            "   class_021     0.0000    0.0000    0.0000        82\n",
            "   class_022     0.1111    0.0115    0.0208        87\n",
            "   class_023     0.1250    0.0114    0.0208        88\n",
            "   class_024     0.0909    0.0104    0.0187        96\n",
            "   class_025     0.0682    0.0588    0.0632        51\n",
            "   class_026     0.1250    0.0300    0.0484       100\n",
            "   class_027     0.4000    0.0152    0.0292       132\n",
            "   class_028     0.0000    0.0000    0.0000        60\n",
            "   class_029     0.1667    0.0364    0.0597        55\n",
            "   class_030     0.0000    0.0000    0.0000        64\n",
            "   class_031     0.0000    0.0000    0.0000        82\n",
            "   class_032     0.0211    0.0278    0.0240        72\n",
            "   class_033     0.0000    0.0000    0.0000        79\n",
            "   class_034     0.0435    0.0580    0.0497        69\n",
            "   class_035     0.0400    0.0833    0.0541        72\n",
            "   class_036     0.0348    0.0941    0.0508        85\n",
            "   class_037     0.0000    0.0000    0.0000        64\n",
            "   class_038     0.0000    0.0000    0.0000        57\n",
            "   class_039     0.1034    0.0309    0.0476        97\n",
            "   class_040     0.1364    0.0294    0.0484       102\n",
            "   class_041     0.1111    0.0392    0.0580       102\n",
            "   class_042     0.0435    0.0103    0.0167        97\n",
            "   class_043     0.0714    0.0104    0.0182        96\n",
            "   class_044     0.0326    0.0375    0.0349        80\n",
            "   class_045     0.1150    0.1585    0.1333        82\n",
            "   class_046     0.0000    0.0000    0.0000        54\n",
            "   class_047     0.0400    0.0702    0.0510        57\n",
            "   class_048     0.0000    0.0000    0.0000        55\n",
            "   class_049     0.0132    0.0172    0.0149        58\n",
            "   class_050     0.1154    0.0283    0.0455       106\n",
            "   class_051     0.0000    0.0000    0.0000        83\n",
            "   class_052     0.0405    0.2143    0.0682        56\n",
            "   class_053     0.0345    0.0290    0.0315        69\n",
            "   class_054     0.0303    0.0233    0.0263        86\n",
            "   class_055     0.0000    0.0000    0.0000        52\n",
            "   class_056     0.0874    0.1765    0.1169        51\n",
            "   class_057     0.0179    0.1400    0.0318        50\n",
            "   class_058     0.0000    0.0000    0.0000        71\n",
            "   class_059     0.0000    0.0000    0.0000        67\n",
            "   class_060     0.0000    0.0000    0.0000        52\n",
            "   class_061     0.1111    0.0370    0.0556        54\n",
            "   class_062     0.0000    0.0000    0.0000        61\n",
            "   class_063     0.0649    0.3636    0.1102        55\n",
            "   class_064     0.0000    0.0000    0.0000        53\n",
            "   class_065     0.0000    0.0000    0.0000        52\n",
            "   class_066     0.0272    0.3400    0.0504        50\n",
            "   class_067     0.0357    0.0169    0.0230        59\n",
            "   class_068     0.0312    0.0200    0.0244        50\n",
            "   class_069     0.0000    0.0000    0.0000        59\n",
            "   class_070     0.0419    0.4902    0.0773        51\n",
            "   class_071     0.0526    0.2000    0.0833        50\n",
            "   class_072     0.0347    0.2600    0.0612        50\n",
            "   class_073     0.0435    0.0185    0.0260        54\n",
            "   class_074     0.0508    0.0600    0.0550        50\n",
            "   class_075     0.0000    0.0000    0.0000        50\n",
            "   class_076     0.0230    0.0385    0.0288        52\n",
            "   class_077     0.0000    0.0000    0.0000        53\n",
            "   class_078     0.0333    0.5741    0.0629        54\n",
            "   class_079     0.0354    0.1159    0.0542        69\n",
            "   class_080     0.0275    0.0526    0.0361        57\n",
            "   class_081     0.0000    0.0000    0.0000        53\n",
            "   class_082     0.0550    0.2400    0.0896        50\n",
            "   class_083     0.2000    0.0600    0.0923        50\n",
            "   class_084     0.1250    0.0577    0.0789        52\n",
            "   class_085     0.0000    0.0000    0.0000        52\n",
            "   class_086     0.0769    0.0200    0.0317        50\n",
            "   class_087     0.2143    0.0357    0.0612        84\n",
            "   class_088     0.2000    0.0294    0.0513        68\n",
            "   class_089     0.1944    0.1186    0.1474       118\n",
            "   class_090     0.1020    0.0980    0.1000        51\n",
            "   class_091     0.3571    0.0490    0.0862       102\n",
            "   class_092     0.0000    0.0000    0.0000        51\n",
            "   class_093     0.0000    0.0000    0.0000        56\n",
            "   class_094     0.1429    0.0385    0.0606        52\n",
            "   class_095     0.0000    0.0000    0.0000        59\n",
            "   class_096     0.0000    0.0000    0.0000        56\n",
            "   class_097     0.1154    0.0429    0.0625        70\n",
            "   class_098     0.0000    0.0000    0.0000        50\n",
            "   class_099     0.0000    0.0000    0.0000        78\n",
            "   class_100     0.1250    0.0109    0.0200        92\n",
            "   class_101     0.0938    0.1800    0.1233        50\n",
            "   class_102     0.0938    0.0275    0.0426       109\n",
            "   class_103     0.0000    0.0000    0.0000       100\n",
            "   class_104     0.2079    0.1909    0.1991       110\n",
            "   class_105     0.0000    0.0000    0.0000        95\n",
            "   class_106     0.0417    0.0088    0.0146       113\n",
            "   class_107     0.0000    0.0000    0.0000       118\n",
            "   class_108     0.4667    0.0588    0.1045       119\n",
            "   class_109     0.0909    0.0312    0.0465        96\n",
            "   class_110     0.0357    0.0345    0.0351        58\n",
            "   class_111     0.0511    0.1321    0.0737        53\n",
            "   class_112     0.0333    0.0123    0.0180        81\n",
            "   class_113     0.0000    0.0000    0.0000        55\n",
            "   class_114     0.0265    0.0980    0.0417        51\n",
            "   class_115     0.0682    0.0545    0.0606        55\n",
            "   class_116     0.0517    0.0508    0.0513        59\n",
            "   class_117     1.0000    0.0182    0.0357        55\n",
            "   class_118     0.0400    0.1071    0.0583        56\n",
            "   class_119     0.0519    0.2200    0.0840        50\n",
            "   class_120     0.1875    0.0870    0.1188        69\n",
            "\n",
            "    accuracy                         0.0541      8580\n",
            "   macro avg     0.0754    0.0594    0.0385      8580\n",
            "weighted avg     0.0852    0.0541    0.0393      8580\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}